"""
    pglmm(nullmode, plinkfile; kwargs...)
# Positional arguments 
- `nullmodel`: null model obtained by fitting pglmm_null.
- `plinkfile::AbstractString`: PLINK file name containing genetic information,
    without the .bed, .fam, or .bim extensions. Moreover, bed, bim, and fam file with 
    the same `geneticfile` prefix need to exist.
# Keyword arguments
- `snpfile::Union{Nothing, AbstractString}`: TXT file name containing genetic data if not in PLINK format.
- `snpmodel`: `ADDITIVE_MODEL` (default), `DOMINANT_MODEL`, or `RECESSIVE_MODEL`.
- `snpinds::Union{Nothing,AbstractVector{<:Integer}}`: SNP indices for bed/vcf file.
- `geneticrowinds::Union{Nothing,AbstractVector{<:Integer}}`: sample indices for bed/vcf file.
- `irwls_tol::Float64` = 1e-7 (default)`: tolerance for the IRWLS loop.
- `irwls_maxiter::Integer = 500 (default)`: maximum number of iterations for the IRWLS loop.
- `K_::Union{Nothing, Integer} = nothing (default)`: stop the full lasso path search after K_th value of Î».
- `verbose::Bool = false (default)`: print number of irwls iterations at each value of Î».
- `standardize_X::Bool = true (default)`: standardize non-genetic covariates. Coefficients are returned on original scale.
- `standardize_G::Bool = true (default)`: standardize genetic predictors. Coefficients are returned on original scale.
- `standardize_weights::Bool = false (default)`: standardize weights so their sum is equal to 1.
- `criterion`: criterion for coordinate descent convergence. Can be equal to `:coef` (default) or `:obj`.
- `earlystop::Bool = true (default)`: should full lasso path search stop earlier if deviance change is smaller than MIN_DEV_FRAC_DIFF or higher than MAX_DEV_FRAC ? 
"""
function pglmm(
    # positional arguments
    nullmodel,
    plinkfile::Union{Nothing, AbstractString} = nothing;
    # keyword arguments
    snpfile::Union{Nothing, AbstractString} = nothing,
    snpmodel = ADDITIVE_MODEL,
    snpinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
    geneticrowinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
    irwls_tol::Float64 = 1e-7,
    irwls_maxiter::Integer = 500,
    K_::Union{Nothing, Integer} = nothing,
    verbose::Bool = false,
    standardize_X::Bool = true,
    standardize_G::Bool = true,
    standardize_weights::Bool = false,
    criterion = :coef,
    earlystop::Bool = true,
    kwargs...
    )

    # Read genotype file
    if !isnothing(plinkfile)
        # read PLINK files
        geno = SnpArray(plinkfile * ".bed")
        
        # Convert genotype file to matrix, convert to additive model (default) and impute
        snpinds = isnothing(snpinds) ? (1:size(geno, 2)) : snpinds 
        geneticrowinds = isnothing(geneticrowinds) ? (1:size(geno, 1)) : geneticrowinds
        G = convert(Matrix{Float64}, @view(geno[geneticrowinds, snpinds]), model = snpmodel, impute = true)
    elseif !isnothing(snpfile)
        # read CSV file
        geno = CSV.read(snpfile, DataFrame)
        
        # Convert genotype file to matrix, convert to additive model (default) and impute
        snpinds = isnothing(snpinds) ? (1:size(geno, 2)) : snpinds 
        geneticrowinds = isnothing(geneticrowinds) ? (1:size(geno, 1)) : geneticrowinds
        G = convert.(Float64, Matrix(geno[geneticrowinds, snpinds]))
    end

    # Initialize number of subjects and predictors (including intercept)
    (n, p), k = size(G), size(nullmodel.X, 2)
    @assert n == length(nullmodel.y) "Genotype matrix and y must have same number of rows"

    # standardize non-genetic covariates and genetic predictors
    intercept = all(nullmodel.X[:,1] .== 1)
    X, muX, sX = standardizeX(nullmodel.X, standardize_X, intercept)
    G, muG, sG = standardizeX(G, standardize_G)

    # Initialize Î² and penalty factors
    Î² = sparse([nullmodel.Î±; zeros(p)])
    p_f = [zeros(k); ones(p)]

    # Spectral decomposition of sum(Ï„ * V)
    eigvals, U = eigen(nullmodel.Ï„V)

    # Define (normalized) weights for each observation
    w = eigenweights(nullmodel.family, eigvals, nullmodel.Ï†)
    w_n = standardize_weights ? w / sum(w) : w

    # Initialize working variable and mean vector and initialize null deviance 
    # based on model with intercept only and no random effects
    y = nullmodel.y
    if nullmodel.family == Binomial()
        Î¼, ybar = GLM.linkinv.(LogitLink(), nullmodel.Î·), mean(y)
        Ytilde = nullmodel.Î· + 4 * (y - Î¼)
        nulldev = -2 * sum(y * log(ybar / (1 - ybar)) .+ log(1 - ybar))
    elseif nullmodel.family == Normal()
        Ytilde = y
        nulldev = var(y) * (n - 1) / nullmodel.Ï†
    end

    # Calculate U * Diagonal(w)
    UD_inv = U * Diagonal(w)

    # Transform X and G
	Xstar = Umul!(U, X, K = 1)
    Gstar = Umul!(U, G)

    # Transform Y
    Ystar = Array{Float64}(undef, n)
	mul!(Ystar, U', Ytilde)

    # Initialize residuals
    r = Ystar - Xstar * Î².nzval

    # Sequence of Î»
    Î»_seq, K = lambda_seq(Ystar, Xstar, Gstar; weights = w_n, p_f = p_f)
    K = isnothing(K_) ? K : K_
    
    # Fit penalized model
    path = pglmm_fit(nullmodel.family, Ytilde, y, Xstar, Gstar, nulldev, r, w, Î², p_f, Î»_seq, K, UD_inv, U, verbose, irwls_tol, irwls_maxiter, criterion, earlystop)

    # If there is an intercept, separate it from betas
    if intercept
        a0 = view(path.betas, 1, :)
        betas = view(path.betas, 2:(p + k), :)
        k = k - 1
    else
        a0 = zeros(p + k)
        betas = path.betas
    end

    # Return coefficients on original scale
    if !isempty(sX) & !isempty(sG)
        lmul!(inv(Diagonal(vec([sX; sG]))), betas)
        if intercept
            a0 .-= vec([muX; muG]' * betas)
        end
    elseif !isempty(sX)
        betas[1:k,:] = lmul!(inv(Diagonal(vec(sX))), betas[1:k,:])
        if intercept
            a0 .-=  vec(muX' * betas[1:k,:])
        end
    elseif !isempty(sG)
        betas[(k+1):end,:] = lmul!(inv(Diagonal(vec(sG))), betas[(k+1):end,:])
        if intercept
            a0 .-=  vec(muG' * betas[(k+1):end,:])
        end
    end

    # Return lasso path
    pglmmPath(nullmodel.family, a0, betas, nulldev, path.pct_dev, path.Î», 0, path.fitted_values, y, UD_inv, nullmodel.Ï„, intercept)
end

# Controls early stopping criteria with automatic Î»
const MIN_DEV_FRAC_DIFF = 1e-5
const MAX_DEV_FRAC = 0.999

# Function to fit a penalised mixed model
function pglmm_fit(
    ::Binomial,
    Ytilde::Vector{Float64},
    y::Vector{Int64},
    Xstar::Matrix{Float64},
    Gstar::Matrix{Float64},
    nulldev::Float64,
    r::Vector{Float64},
    w::Vector{Float64},
    Î²::SparseVector{Float64, Int64},
    p_f::Vector{Float64},
    Î»_seq::Vector{Float64},
    K::Int64,
    UD_inv::Matrix{Float64},
    U::Matrix{Float64},
    verbose::Bool,
    irwls_tol::Float64,
    irwls_maxiter::Int64,
    criterion,
    earlystop::Bool
)
    # Initialize array to store output for each Î»
    betas = zeros(length(Î²), K)
    pct_dev = zeros(Float64, K)
    dev_ratio = convert(Float64, NaN)
    fitted_means = zeros(length(y), K)
    Î¼ = zeros(length(y))

    # Loop through sequence of Î»
    i = 0
    for _ = 1:K
        # Next iterate
        i += 1
        converged = false
        
        # Current value of Î»
        Î» = Î»_seq[i]

        # Initialize objective function and save previous deviance ratio
        dev = loss = convert(Float64, Inf)
        last_dev_ratio = dev_ratio
        
        # Penalized iterative weighted least squares (IWLS)
        for irwls in 1:irwls_maxiter

            # Run coordinate descent inner loop to update Î² and r
            Î², r = cd_lasso(r, Xstar, Gstar; family = Binomial(), Ytilde = Ytilde, y = y, w = w, UD_inv = UD_inv, Î² = Î², p_f = p_f, Î» = Î», criterion = criterion)

            # Update Î¼
            Î¼ = updateÎ¼(r, Ytilde, UD_inv)
            
            # Update deviance and loss function
            prev_loss = loss
            dev = LogisticDeviance(y, r, w, Î¼)
            loss = dev/2 + Î» * sum(p_f[Î².nzind] .* abs.(Î².nzval))
            
            # If loss function did not decrease, take a half step to ensure convergence
            if loss > prev_loss + length(Î¼)*eps(prev_loss)
                verbose && println("step-halving because loss=$loss > $prev_loss + $(length(Î¼)*eps(prev_loss)) = length(Î¼)*eps(prev_loss)")
                #= s = 1.0
                d = Î² - Î²_last
                while loss > prev_loss
                    s /= 2
                    Î² = Î²_last + s * d
                    Î¼ = updateÎ¼(r, Ytilde, UD_inv) 
                    dev = LogisticDeviance(y, r, w, Î¼)
                    loss = dev/2 + Î» * sum(p_f[Î².nzind] .* abs.(Î².nzval))
                end =#
            end 

            # Update working response and residuals
            Ytilde, r = wrkresp(y, r, Î¼, Ytilde, U)

            # Check termination conditions
            converged = abs(loss - prev_loss) < irwls_tol * loss
            converged && verbose && println("Number of irwls iterations = $irwls at $i th value of Î».")
            converged && break 

        end
        @assert converged "IRWLS failed to converge in $irwls_maxiter iterations at Î» = $Î»"

        # Store ouput from IRWLS loop
        betas[:, i] = convert(Vector{Float64}, Î²)
        dev_ratio = dev/nulldev
        pct_dev[i] = 1 - dev_ratio
        fitted_means[:, i] = Î¼

        # Test whether we should continue
        earlystop && ((last_dev_ratio - dev_ratio < MIN_DEV_FRAC_DIFF && length(Î².nzind) > sum(p_f .==0)) || pct_dev[i] > MAX_DEV_FRAC) && break
    end

    return(betas = view(betas, :, 1:i), pct_dev = pct_dev[1:i], Î» = Î»_seq[1:i], fitted_values = view(fitted_means, :, 1:i))
end

function pglmm_fit(
    ::Normal,
    Ytilde::Vector{Float64},
    y::Vector{Float64},
    Xstar::Matrix{Float64},
    Gstar::Matrix{Float64},
    nulldev::Float64,
    r::Vector{Float64},
    w::Vector{Float64},
    Î²::SparseVector{Float64, Int64},
    p_f::Vector{Float64},
    Î»_seq::Vector{Float64},
    K::Int64,
    UD_inv::Matrix{Float64},
    U::Matrix{Float64},
    verbose::Bool,
    irwls_tol::Float64,
    irwls_maxiter::Int64,
    criterion,
    earlystop::Bool 
)
    # Initialize array to store output for each Î»
    betas = zeros(length(Î²), K)
    pct_dev = zeros(Float64, K)
    dev_ratio = convert(Float64, NaN)
    residuals = zeros(length(y), K)
    fitted_means = zeros(length(y), K)

    # Loop through sequence of Î»
    i = 0
    for _ = 1:K
        # Next iterate
        i += 1

        # Print current iteration
        verbose && println("i = ", i)
        
        # Current value of Î»
        Î» = Î»_seq[i]

        # Save previous deviance ratio
        last_dev_ratio = dev_ratio

        # Run coordinate descent inner loop to update Î² and r
        Î², r = cd_lasso(r, Xstar, Gstar; family = Normal(), Ytilde = Ytilde, y = y, w = w, UD_inv = UD_inv, Î² = Î², p_f = p_f, Î» = Î», criterion = criterion)

        # Update deviance
        dev = NormalDeviance(r, w)

        # Store ouput
        betas[:, i] = convert(Vector{Float64}, Î²)
        dev_ratio = dev/nulldev
        pct_dev[i] = 1 - dev_ratio
        residuals[:, i] = r

        # Test whether we should continue
        earlystop && ((last_dev_ratio - dev_ratio < MIN_DEV_FRAC_DIFF && length(Î².nzind) > sum(p_f .==0))|| pct_dev[i] > MAX_DEV_FRAC) && break
    end

    return(betas = view(betas, :, 1:i), pct_dev = pct_dev[1:i], Î» = Î»_seq[1:i], fitted_values = view(fitted_means, :, 1:i))
end

# Function to perform coordinate descent with a lasso penalty
function cd_lasso(
    # positional arguments
    r::Vector{Float64},
    X::Matrix{Float64},
    G::Matrix{Float64};
    #keywords arguments
    family::UnivariateDistribution,
    Î²::SparseVector{Float64},
    Ytilde::Vector{Float64},
    y::Union{Vector{Int64},Vector{Float64}},
    w::Vector{Float64}, 
    UD_inv::Matrix{Float64},
    p_f::Vector{Float64}, 
    Î»::Float64,
    cd_maxiter::Integer = 100000,
    cd_tol::Real=1e-8,
    criterion
    )

    converged = false
    maxÎ” = zero(Float64)
    loss = Inf
    k = size(X, 2)

    for cd_iter in 1:cd_maxiter
        # At first iteration, perform one coordinate cycle and 
        # record active set of coefficients that are nonzero
        if cd_iter == 1 || converged
            # Non-genetic covariates
            for j in 1:k
                Xj = view(X, :, j)
                v = dot(Xj, Diagonal(w), r)
                Î»j = Î» * p_f[j]
                Swxxj = dot(Xj, Diagonal(w), Xj)

                last_Î² = Î²[j]
                if last_Î² != 0
                    v += last_Î² * Swxxj
                else
                    # Adding a new variable to the model
                    abs(v) < Î»j && continue
                end
                new_Î² = softtreshold(v, Î»j) / Swxxj
                r += Xj * (last_Î² - new_Î²)

                maxÎ” = max(maxÎ”, Swxxj * (last_Î² - new_Î²)^2)
                Î²[j] = new_Î²
            end

            # Genetic covariates
            for j in 1:size(G, 2)
                Gj = view(G, :, j)
                v = dot(Gj, Diagonal(w), r)
                Î»j = Î» * p_f[k + j]
                Swxxj = dot(Gj, Diagonal(w), Gj)

                last_Î² = Î²[k + j]
                if last_Î² != 0
                    v += last_Î² * Swxxj
                else
                    # Adding a new variable to the model
                    abs(v) < Î»j && continue
                end
                new_Î² = softtreshold(v, Î»j) / Swxxj
                r += Gj * (last_Î² - new_Î²)

                maxÎ” = max(maxÎ”, Swxxj * (last_Î² - new_Î²)^2)
                Î²[k + j] = new_Î²
            end

            # Check termination condition at last iteration
            if criterion == :obj
                # Update Î¼
                Î¼ = updateÎ¼(r, Ytilde, UD_inv)

                # Update deviance and loss function
                prev_loss = loss
                dev = model_dev(family, y, r, w, Î¼)
                loss = dev/2 + Î» * sum(p_f[Î².nzind] .* abs.(Î².nzval))

                # Check termination condition
                converged && abs(loss - prev_loss) < cd_tol * loss && break

            elseif criterion == :coef
                converged && maxÎ” < cd_tol && break
            end
        end

        # Cycle over coefficients in active set only until convergence
        maxÎ” = zero(Float64)
        
        # Non-genetic covariates
        for j in Î².nzind[Î².nzind .<= k]
            last_Î² = Î²[j]
            last_Î² == 0 && continue
            
            Xj = view(X, :, j)
            Swxxj = dot(Xj, Diagonal(w), Xj)
            v = dot(Xj, Diagonal(w), r) + last_Î² * Swxxj
            new_Î² = softtreshold(v, Î» * p_f[j]) / Swxxj
            r += Xj * (last_Î² - new_Î²)

            maxÎ” = max(maxÎ”, Swxxj * (last_Î² - new_Î²)^2)
            Î²[j] = new_Î²
        end

        # Genetic predictors
        for j in Î².nzind[Î².nzind .> k]
            last_Î² = Î²[j]
            last_Î² == 0 && continue
            
            Gj = view(G, :, j-k)
            Swxxj = dot(Gj, Diagonal(w), Gj)
            v = dot(Gj, Diagonal(w), r) + last_Î² * Swxxj
            new_Î² = softtreshold(v, Î» * p_f[j]) / Swxxj
            r += Gj * (last_Î² - new_Î²)

            maxÎ” = max(maxÎ”, Swxxj * (last_Î² - new_Î²)^2)
            Î²[j] = new_Î²
        end

        # Check termination condition before last iteration
        if criterion == :obj
            # Update Î¼
            Î¼ = updateÎ¼(r, Ytilde, UD_inv)

            # Update deviance and loss function
            prev_loss = loss
            dev = model_dev(family, y, r, w, Î¼)
            loss = dev/2 + Î» * sum(p_f[Î².nzind] .* abs.(Î².nzval))

            # Check termination condition
            converged = abs(loss - prev_loss) < cd_tol * loss 

        elseif criterion == :coef
            converged = maxÎ” < cd_tol
        end
    end

    # Assess convergence of coordinate descent
    @assert converged "Coordinate descent failed to converge in $cd_maxiter iterations at Î» = $Î»"

    return(Î², r)

end

modeltype(::Normal) = "Least Squares GLMNet"
modeltype(::Binomial) = "Logistic"

eigenweights(::Normal, eigvals::Vector{Float64}, Ï†::Float64) = (1 ./(Ï† .+ eigvals))
eigenweights(::Binomial, eigvals::Vector{Float64}, Ï†::Float64) = (1 ./(4 .+ eigvals))

struct pglmmPath{F<:Distribution, A<:AbstractArray, B<:AbstractArray}
    family::F
    a0::A                                       # intercept values for each solution
    betas::B                                    # coefficient values for each solution
    null_dev::Float64                           # Null deviance of the model
    pct_dev::Vector{Float64}                    # R^2 values for each solution
    lambda::Vector{Float64}                     # lamda values corresponding to each solution
    npasses::Int                                # actual number of passes over the
                                                # data for all lamda values
    fitted_values                               # fitted_values
    y::Union{Vector{Int64}, Vector{Float64}}    # eigenvalues vector
    UD_inv::Matrix{Float64}                     # eigenvectors matrix times diagonal weights matrix
    Ï„::Vector{Float64}                        	# estimated variance components
    intercept::Bool				# boolean for intercept
end

function show(io::IO, g::pglmmPath)
    df = [length(findall(x -> x != 0, vec(view(g.betas, :,k)))) for k in 1:size(g.betas, 2)]
    println(io, "$(modeltype(g.family)) Solution Path ($(size(g.betas, 2)) solutions for $(size(g.betas, 1)) predictors):") #in $(g.npasses) passes):"
    print(io, CoefTable(Union{Vector{Int},Vector{Float64}}[df, g.pct_dev, g.lambda], ["df", "pct_dev", "Î»"], []))
end

# Function to compute sequence of values for Î»
function lambda_seq(
    y::Vector{Float64}, 
    X::Matrix{Float64},
    G::Matrix{Float64}; 
    weights::Vector{Float64},
    p_f::Vector{Float64},
    K::Integer = 100
    )

    Î»_min_ratio = (length(y) < size(G, 2) ? 1e-2 : 1e-4)
    Î»_max = lambda_max(X, y, weights, p_f[1:size(X, 2)])
    Î»_max = lambda_max(G, y, weights, p_f[(size(X, 2) + 1):end], Î»_max)
    Î»_min = Î»_max * Î»_min_ratio
    Î»_step = log(Î»_min_ratio)/(K - 1)
    Î»_seq = exp.(collect(log(Î»_max):Î»_step:log(Î»_min)))
    
    return(Î»_seq, length(Î»_seq))
end

# Function to compute Î»_max
function lambda_max(X::AbstractMatrix{T}, y::AbstractVector{T}, w::AbstractVector{T}, p_f::AbstractVector{T}, Î»_max::T = zero(T)) where T

    wY = w .* y
    seq = findall(x-> x != 0, p_f)
    for j in seq
        x = abs(dot(view(X, :,j), wY))
        if x > Î»_max
            Î»_max = x
        end
    end
    return(Î»_max)
end

# Define Softtreshold function
function  softtreshold(z::Float64, Î³::Float64) :: Float64
    if z > Î³
        z - Î³
    elseif z < -Î³
        z + Î³
    else
        0
    end
end

# Function to update working response and residual
function wrkresp(
    y::Vector{Int64},
    r::Vector{Float64},
    Î¼::Vector{Float64},
    Ytilde::Vector{Float64},
    U::Matrix{Float64}
)
    Î· = GLM.linkfun.(LogitLink(), Î¼)
    r += U' * (Î· + 4 * (y - Î¼) - Ytilde)
    Ytilde = Î· + 4 * (y - Î¼)
    return(Ytilde, r)
end

# Function to update linear predictor and mean at each iteration
const PMIN = 1e-5
const PMAX = 1-1e-5
function updateÎ¼(r::Vector{Float64}, Ytilde::Vector{Float64}, UD_inv::Matrix{Float64})
    Î· = Ytilde - 4 * UD_inv * r
    Î¼ = GLM.linkinv.(LogitLink(), Î·)
    Î¼ = [Î¼[i] < PMIN ? PMIN : Î¼[i] > PMAX ? PMAX : Î¼[i] for i in 1:length(Î¼)]
    return(Î¼)
end

# Functions to calculate deviance
model_dev(::Binomial, y::Vector{Int64}, r::Vector{Float64}, w::Vector{Float64}, Î¼::Vector{Float64}) = LogisticDeviance(y, r, w, Î¼)
model_dev(::Normal, y::Vector{Float64}, r::Vector{Float64}, w::Vector{Float64}, Î¼::Vector{Float64}) = NormalDeviance(r, w)

function LogisticDeviance(y::Vector{Int64}, r::Vector{Float64}, w::Vector{Float64}, Î¼::Vector{Float64})
    -2 * sum(y .* log.(Î¼ ./ (1 .- Î¼)) .+ log.(1 .- Î¼)) + sum(w .* (1 .- 4 * w) .* r.^2)
end

function NormalDeviance(r::Vector{Float64}, w::Vector{Float64})
    dot(r, Diagonal(w), r)
end

# Standardize predictors for lasso
function standardizeX(X::AbstractMatrix{T}, standardize::Bool, intercept::Bool = false) where T
    mu = intercept ? vec([0 mean(X[:,2:end], dims = 1)]) : vec(mean(X, dims = 1))
    if standardize
        s = vec(std(X, dims = 1, corrected = false))
        if any(s .== zero(T))
            !intercept && @warn("One predictor is a constant, hence it can't been standardized!")
            s[s .== 0] .= 1 
        end
        for j in 1:size(X,2), i in 1:size(X, 1) 
            @inbounds X[i,j] = (X[i,j] .- mu[j]) / s[j]
        end
    else
        for j in 1:size(X,2), i in 1:size(X, 1) 
            @inbounds X[i,j] = X[i,j] .- mu[j]
        end
        s = []
    end

    # Remove first term if intercept
    if intercept 
         popfirst!(mu); popfirst!(s)
    end

    X, mu, s
end

# Predict phenotype
function predict(path::pglmmPath, 
                  X::AbstractMatrix{T}, 
                  grmfile::AbstractString; 
                  grmrowinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  grmcolinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  M::Union{Nothing, Vector{Any}} = nothing,
                  s::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  fixed_effects_only::Bool = false,
                  outtype = :response
                 ) where T

    # read file containing the m x (N-m) kinship matrix between m test and (N-m) training subjects
    GRM = open(GzipDecompressorStream, grmfile, "r") do stream
        Symmetric(Matrix(CSV.read(stream, DataFrame)))
    end

    if !isnothing(grmrowinds)
        GRM = GRM[grmrowinds, :]
    end

    if !isnothing(grmcolinds)
        GRM = GRM[:, grmcolinds]
    end

    # Covariance matrix between test and training subjects
    V = isnothing(M) ? push!(Any[], GRM) : reverse(push!(M, GRM))
    Î£_12 = sum(path.Ï„ .* V)

    # Number of predictions to compute. User can provide index s for which to provide predictions, 
    # rather than computing predictions for the whole path.
    s = isnothing(s) ? (1:size(path.betas, 2)) : s

    # Linear predictor
    Î· = path.a0[s]' .+ X * path.betas[:,s]

    if fixed_effects_only == false
        if path.family == Binomial()
            Î· += Î£_12 * (path.y .- path.fitted_values[:,s])
        elseif path.family == Normal()
            Î· += Î£_12 * path.UD_inv * path.fitted_values[:,s]
        end
    end

    # Return linear predictor (default) or fitted probs
    if outtype == :response
        return(Î·)
    elseif outtype == :prob
        return(GLM.linkinv.(LogitLink(), Î·))
    end
end 

# GIC penalty parameter
function GIC(path::pglmmPath, criterion)
    
    # Obtain number of rows (n), predictors (p) and Î» values (K)
    n = size(path.y, 1)
    p, K = size(path.betas)
    df = path.intercept .+ [length(findall(x -> x != 0, vec(view(path.betas, :, k)))) for k in 1:K] .+ length(path.Ï„)

    # Define GIC criterion
    if criterion == :BIC
        a_n = log(n)
    elseif criterion == :AIC
        a_n = 2
    elseif criterion == :HDBIC
        a_n = log(log(n)) * log(p)
    end

    # Compute deviance for each value of Î»
    dev = (1 .- path.pct_dev) * path.null_dev
    GIC = dev .+ a_n * df

    # Return betas with lowest GIC value
    return(argmin(GIC))
end

# In-place multiplication of predictor matrix with eigenvectors matrix U'
function Umul!(U::AbstractMatrix{T}, X::AbstractMatrix{T}; K::Integer = 1000) where T
    n, p = size(X)
    b = similar(X, n, K)
    jseq = collect(1:K:p)[1:(end-1)]

    @inbounds for j in jseq
        X[:, j:(j+K-1)] = mul!(b, U', view(X, :, j:(j+K-1)))
    end

    lastt = 0
    if (length(jseq)>0)
            lastt = last(jseq)
    end
    # b = similar(X, n, length((last(jseq) + K):p))
    # X[:, (last(jseq) + K):p] = mul!(b, U', view(X, :, (last(jseq) + K):p))
    b = similar(X, n, length((lastt + K):p))
    X[:, (lastt + K):p] = mul!(b, U', view(X, :, (lastt + K):p))
    return(X)
end