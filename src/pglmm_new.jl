"""
    pglmm(nullmode, plinkfile; kwargs...)
# Positional arguments 
- `nullmodel`: null model obtained by fitting pglmm_null.
- `plinkfile::AbstractString`: PLINK file name containing genetic information,
    without the .bed, .fam, or .bim extensions. Moreover, bed, bim, and fam file with 
    the same `geneticfile` prefix need to exist.
# Keyword arguments
- `snpfile::Union{Nothing, AbstractString}`: TXT file name containing genetic data if not in PLINK format.
- `snpmodel`: `ADDITIVE_MODEL` (default), `DOMINANT_MODEL`, or `RECESSIVE_MODEL`.
- `snpinds::Union{Nothing,AbstractVector{<:Integer}}`: SNP indices for bed/vcf file.
- `geneticrowinds::Union{Nothing,AbstractVector{<:Integer}}`: sample indices for bed/vcf file.
- `irls_tol::Float64` = 1e-7 (default)`: tolerance for the irls loop.
- `irls_maxiter::Integer = 500 (default)`: maximum number of iterations for the irls loop.
- `K_::Union{Nothing, Integer} = nothing (default)`: stop the full lasso path search after K_th value of Î».
- `verbose::Bool = false (default)`: print number of irls iterations at each value of Î».
- `standardize_X::Bool = true (default)`: standardize non-genetic covariates. Coefficients are returned on original scale.
- `standardize_G::Bool = true (default)`: standardize genetic predictors. Coefficients are returned on original scale.
- `criterion`: criterion for coordinate descent convergence. Can be equal to `:coef` (default) or `:obj`.
- `earlystop::Bool = true (default)`: should full lasso path search stop earlier if deviance change is smaller than MIN_DEV_FRAC_DIFF or higher than MAX_DEV_FRAC ? 
- `method = cd (default)`: which method to use to estimate random effects vector. Can be equal to `:cd` (default) for coordinate descent or `:conjgrad` for conjuguate gradient descent.  
"""
function pglmm(
    # positional arguments
    nullmodel,
    plinkfile::Union{Nothing, AbstractString} = nothing;
    # keyword arguments
    snpfile::Union{Nothing, AbstractString} = nothing,
    snpmodel = ADDITIVE_MODEL,
    snpinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
    geneticrowinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
    irls_tol::Float64 = 1e-7,
    irls_maxiter::Integer = 500,
    K::Integer = 100,
    verbose::Bool = false,
    standardize_X::Bool = true,
    standardize_G::Bool = true,
    criterion = :coef,
    earlystop::Bool = true,
    method = :cd,
    kwargs...
    )

    ## keyword arguments
    # snpmodel = ADDITIVE_MODEL
    # snpinds = nothing
    # geneticrowinds = trainrowinds
    # irls_tol = 1e-7
    # irls_maxiter = 500
    # K = 100
    # verbose = true
    # standardize_X = true
    # standardize_G = true
    # criterion = :coef
    # earlystop= true
    # method = :cd 

    # Read genotype file
    if !isnothing(plinkfile)

	    # read PLINK files
	    geno = SnpArray(plinkfile * ".bed")
        snpinds_ = isnothing(snpinds) ? (1:size(geno, 2)) : snpinds 
        geneticrowinds_ = isnothing(geneticrowinds) ? (1:size(geno, 1)) : geneticrowinds
        
        # Read genotype and calculate mean and standard deviation
	    G = SnpLinAlg{Float64}(geno, model = snpmodel, impute = true, center = true, scale = standardize_G) |> x-> @view(x[geneticrowinds_, snpinds_])
        muG, sG = standardizeG(@view(geno[geneticrowinds_, snpinds_]), snpmodel, standardize_G)

    elseif !isnothing(snpfile)

        # read CSV file
        geno = CSV.read(snpfile, DataFrame)
        
        # Convert genotype file to matrix, convert to additive model (default) and impute
        snpinds_ = isnothing(snpinds) ? (1:size(geno, 2)) : snpinds 
        geneticrowinds_ = isnothing(geneticrowinds) ? (1:size(geno, 1)) : geneticrowinds
        G = convert.(Float64, Matrix(geno[geneticrowinds_, snpinds_]))

	    # standardize genetic predictors
    	G, muG, sG = standardizeX(G, standardize_G)
    end

    # Initialize number of subjects and predictors (including intercept)
    (n, p), k = size(G), size(nullmodel.X, 2)
    @assert n == length(nullmodel.y) "Genotype matrix and y must have same number of rows"

    # Spectral decomposition of sum(Ï„ * V)
    eigvals, U = eigen(nullmodel.Ï„V)
    eigvals .= 1 ./ eigvals
    UD_invUt = U * Diagonal(eigvals) * U'
   
    # Rotate random effects vector 
    Î´ = Array{Float64}(undef, n)
    b = nullmodel.Î· - nullmodel.X * nullmodel.Î±
    mul!(Î´, U', b)

    # Initialize working variable
    y = nullmodel.y
    if nullmodel.family == Binomial()
        Î¼, ybar = GLM.linkinv.(LogitLink(), nullmodel.Î·), mean(y)
        w = Î¼ .* (1 .- Î¼)
        Ytilde = nullmodel.Î· + (y - Î¼) ./ w
        nulldev = -2 * sum(y * log(ybar / (1 - ybar)) .+ log(1 - ybar))
    elseif nullmodel.family == Normal()
        Ytilde, Î¼ = y, nullmodel.Î·
        w = 1 / nullmodel.Ï†
        nulldev = w * (y .- mean(y)).^2
    end

    # Initialize residuals and null deviance
    r = Ytilde - nullmodel.Î·

    # standardize non-genetic covariates
    intercept = all(nullmodel.X[:,1] .== 1)
    X, muX, sX = standardizeX(nullmodel.X, standardize_X, intercept)
    ind_D = !isnothing(nullmodel.ind_D) ? nullmodel.ind_D .- intercept : nothing
    D, muD, sD = !isnothing(ind_D) ? (vec(X[:, nullmodel.ind_D]), muX[ind_D], sX[ind_D]) : repeat([nothing], 3)

    # Initialize Î², Î³ and penalty factors
    Î±, Î², Î³ = sparse(zeros(k)), sparse(zeros(p)), sparse(zeros(p))
    p_fX = zeros(k); p_fG = ones(p)

    # Sequence of Î»
    Î»_seq = lambda_seq(y - Î¼, X, G, D; p_fX = p_fX, p_fG = p_fG)
    
    # Fit penalized model
    path = pglmm_fit(nullmodel.family, Ytilde, y, X, G, U, D, nulldev, r, Î¼, Î±, Î², Î³, Î´, p_fX, p_fG, Î»_seq, K, w, eigvals, verbose, criterion, earlystop, irls_tol, irls_maxiter, method)

    # Separate intercept from coefficients
    a0, alphas = intercept ? (path.alphas[1,:], path.alphas[2:end,:]) : (nothing, path.alphas)
    betas = path.betas
    gammas = !isnothing(D) ? path.gammas : nothing

    # Return coefficients on original scale
    if isnothing(gammas)
        if !isempty(sX) & !isempty(sG)
            lmul!(inv(Diagonal(sX)), alphas), lmul!(inv(Diagonal(sG)), betas)
        elseif !isempty(sX)
            lmul!(inv(Diagonal(sX)), alphas)
        elseif !isempty(sG)
            lmul!(inv(Diagonal(sG)), betas)
        end

        a0 .-= vec(muX' * alphas + muG' * betas)
    else
        if !isempty(sX) & !isempty(sG)
            lmul!(inv(Diagonal(sX)), alphas), lmul!(inv(Diagonal(sG)), betas), lmul!(inv(Diagonal(sD .* sG)), gammas)
        elseif !isempty(sX)
            lmul!(inv(Diagonal(sX)), alphas), lmul!(inv(Diagonal(sD .* ones(p))), gammas)
        elseif !isempty(sG)
            lmul!(inv(Diagonal(sG)), betas), lmul!(inv(Diagonal(sG)), gammas)
        end

        a0 .-= vec(muX' * alphas + muG' * betas - (muD .* muG)' * gammas)
        alphas[ind_D, :] -= muG' * gammas; betas -= muD' .* gammas
    end

    # Return lasso path
    pglmmPath(nullmodel.family, a0, alphas, betas, gammas, nulldev, path.pct_dev, path.Î», 0, path.fitted_values, y, UD_invUt, nullmodel.Ï„, intercept)
end

# Controls early stopping criteria with automatic Î»
const MIN_DEV_FRAC_DIFF = 1e-5
const MAX_DEV_FRAC = 0.999

# Function to fit a penalized mixed model
function pglmm_fit(
    ::Binomial,
    Ytilde::Vector{T},
    y::Vector{Int64},
    X::Matrix{T},
    G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}},
    U::Matrix{T},
    D::Nothing,
    nulldev::T,
    r::Vector{T},
    Î¼::Vector{T},
    Î±::SparseVector{T},
    Î²::SparseVector{T},
    Î³::SparseVector{T},
    Î´::Vector{T},
    p_fX::Vector{T},
    p_fG::Vector{T},
    Î»_seq::Vector{T},
    K::Int64,
    w::Vector{T},
    eigvals::Vector{T},
    verbose::Bool,
    criterion,
    earlystop::Bool,
    irls_tol::T,
    irls_maxiter::Int64,
    method
) where T

    # Initialize array to store output for each Î»
    alphas = zeros(length(Î±), K)
    betas = zeros(length(Î²), K)
    pct_dev = zeros(T, K)
    dev_ratio = convert(T, NaN)
    fitted_means = zeros(length(y), K)

    # Loop through sequence of Î»
    i = 0
    for _ = 1:K
        # Next iterate
        i += 1
        converged = false
        
        # Current value of Î»
        Î» = Î»_seq[i]
        dÎ» = 2 * Î»_seq[i] - Î»_seq[max(1, i-1)]

        # Check strong rule
        compute_strongrule(dÎ», p_fX, p_fG, Î± = Î±, Î² = Î², X = X, G = G, y = y, Î¼ = Î¼)

        # Initialize objective function and save previous deviance ratio
        dev = loss = convert(T, Inf)
        last_dev_ratio = dev_ratio

        # Iterative weighted least squares (IRLS)
        for irls in 1:irls_maxiter

            # Update random effects vector Î´
            update_Î´(Val(method); U = U, Î» = Î», family = Binomial(), Ytilde = Ytilde, y = y, w = w, r = r, Î´ = Î´, eigvals = eigvals, criterion = criterion, Î¼ = Î¼)

            # Run coordinate descent inner loop to update Î²
            Swxx, Swgg = cd_lasso(X, G, Î»; family = Binomial(), Ytilde = Ytilde, y = y, w = w, r = r, Î± = Î±, Î² = Î², Î´ = Î´, p_fX = p_fX, p_fG = p_fG, eigvals = eigvals, criterion = criterion)

            # Update Î¼ and w
            Î¼, w = updateÎ¼(r, Ytilde)
            
            # Update deviance and loss function
            prev_loss = loss
            dev = LogisticDeviance(Î´, eigvals, y, Î¼)
            loss = dev/2 + last(Î») * P(Î±, Î², p_fX, p_fG)
            
            # If loss function did not decrease, take a half step to ensure convergence
            if loss > prev_loss + length(Î¼)*eps(prev_loss)
                verbose && println("step-halving because loss=$loss > $prev_loss + $(length(Î¼)*eps(prev_loss)) = length(Î¼)*eps(prev_loss)")
                #= s = 1.0
                d = Î² - Î²_last
                while loss > prev_loss
                    s /= 2
                    Î² = Î²_last + s * d
                    Î¼, w = updateÎ¼(r, Ytilde) 
                    dev = LogisticDeviance(Î´, eigvals, y, Î¼)
                    loss = dev/2 + last(Î») * P(Î±, Î², p_fX, p_fG)
                end =#
            end 

            # Update working response and residuals
            Ytilde, r = wrkresp(y, Î¼, w)

            # Check termination conditions
            converged = abs(loss - prev_loss) < irls_tol * loss
            
            # Check KKT conditions at last iteration
            if converged
                maxÎ”, converged = cycle(X, G, Î», Val(true), r = r, Î± = Î±, Î² = Î², Swxx = Swxx, Swgg = Swgg, w = w, p_fX = p_fX, p_fG = p_fG)
            end
            converged && verbose && println("Number of irls iterations = $irls at $i th value of Î».")
            converged && break  
        end
        @assert converged "IRLS failed to converge in $irls_maxiter iterations at Î» = $Î»"

        # Store ouput from irls loop
        alphas[:, i] = convert(Vector{Float64}, Î±)
        betas[:, i] = convert(Vector{Float64}, Î²)
        dev_ratio = dev/nulldev
        pct_dev[i] = 1 - dev_ratio
        fitted_means[:, i] = Î¼

        # Test whether we should continue
        earlystop && ((last_dev_ratio - dev_ratio < MIN_DEV_FRAC_DIFF) || pct_dev[i] > MAX_DEV_FRAC) && break
    end

    return(alphas = view(alphas, :, 1:i), betas = view(betas, :, 1:i), pct_dev = pct_dev[1:i], Î» = Î»_seq[1:i], fitted_values = view(fitted_means, :, 1:i))
end

# Function to fit a penalized mixed model
function pglmm_fit(
    ::Binomial,
    Ytilde::Vector{T},
    y::Vector{Int64},
    X::Matrix{T},
    G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}},
    U::Matrix{T},
    D::Vector{T},
    nulldev::T,
    r::Vector{T},
    Î¼::Vector{T},
    Î±::SparseVector{T},
    Î²::SparseVector{T},
    Î³::SparseVector{T},
    Î´::Vector{T},
    p_fX::Vector{T},
    p_fG::Vector{T},
    Î»_seq::Vector{T},
    K::Int64,
    w::Vector{T},
    eigvals::Vector{T},
    verbose::Bool,
    criterion,
    earlystop::Bool,
    irls_tol::T,
    irls_maxiter::Int64,
    method
) where T

    # Initialize array to store output for each Î»
    alphas = zeros(length(Î±), K)
    betas = zeros(length(Î²), K)
    gammas = zeros(length(Î³), K)
    pct_dev = zeros(T, K)
    dev_ratio = convert(T, NaN)
    fitted_means = zeros(length(y), K)

    # Loop through sequence of Î»
    i = 0
    for _ = 1:K
        # Next iterate
        i += 1
        converged = false
        
        # Current value of Î»
        Î» = Î»_seq[i]
        dÎ» = 2 * Î»_seq[i] - Î»_seq[max(1, i-1)]

        # Check strong rule
        compute_strongrule(dÎ», Î»_seq[max(1, i-1)], p_fX, p_fG, D, Î± = Î±, Î² = Î², Î³ = Î³, X = X, G = G, y = y, Î¼ = Î¼)

        # Initialize objective function and save previous deviance ratio
        dev = loss = convert(T, Inf)
        last_dev_ratio = dev_ratio

        # Iterative weighted least squares (IRLS)
        for irls in 1:irls_maxiter

            # Update random effects vector Î´
            update_Î´(Val(method); U = U, Î» = Î», family = Binomial(), Ytilde = Ytilde, y = y, w = w, r = r, Î´ = Î´, eigvals = eigvals, criterion = criterion, Î¼ = Î¼)

            # Run coordinate descent inner loop to update Î²
            Swxx, Swgg, Swdg = cd_lasso(D, X, G, Î»; family = Binomial(), Ytilde = Ytilde, y = y, w = w, r = r, Î± = Î±, Î² = Î², Î´ = Î´, Î³ = Î³, p_fX = p_fX, p_fG = p_fG, eigvals = eigvals, criterion = criterion)

            # Update Î¼ and w
            Î¼, w = updateÎ¼(r, Ytilde)
            
            # Update deviance and loss function
            prev_loss = loss
            dev = LogisticDeviance(Î´, eigvals, y, Î¼)
            loss = dev/2 + last(Î») * P(Î±, Î², Î³, p_fX, p_fG)
            
            # If loss function did not decrease, take a half step to ensure convergence
            if loss > prev_loss + length(Î¼)*eps(prev_loss)
                verbose && println("step-halving because loss=$loss > $prev_loss + $(length(Î¼)*eps(prev_loss)) = length(Î¼)*eps(prev_loss)")
                #= s = 1.0
                d = Î² - Î²_last
                while loss > prev_loss
                    s /= 2
                    Î² = Î²_last + s * d
                    Î¼, w = updateÎ¼(r, Ytilde) 
                    dev = LogisticDeviance(Î´, eigvals, y, Î¼)
                    loss = dev/2 + last(Î») * P(Î±, Î², Î³, p_fX, p_fG)
                end =#
            end 

            # Update working response and residuals
            Ytilde, r = wrkresp(y, Î¼, w)

            # Check termination conditions
            converged = abs(loss - prev_loss) < irls_tol * loss
            
            # Check KKT conditions at last iteration
            if converged
                maxÎ”, converged = cycle(D, X, G, Î», Val(true), r = r, Î± = Î±, Î² = Î², Î³ = Î³, Swxx = Swxx, Swgg = Swgg, Swdg = Swdg, w = w, p_fX = p_fX, p_fG = p_fG)
            end
            converged && verbose && println("Number of irls iterations = $irls at $i th value of Î».")
            converged && break  
        end
        @assert converged "IRLS failed to converge in $irls_maxiter iterations at Î» = $Î»"

        # Store ouput from irls loop
        alphas[:, i] = convert(Vector{Float64}, Î±)
        betas[:, i] = convert(Vector{Float64}, Î²)
        gammas[:, i] = convert(Vector{Float64}, Î³)
        dev_ratio = dev/nulldev
        pct_dev[i] = 1 - dev_ratio
        fitted_means[:, i] = Î¼

        # Test whether we should continue
        earlystop && ((last_dev_ratio - dev_ratio < MIN_DEV_FRAC_DIFF) || pct_dev[i] > MAX_DEV_FRAC) && break
    end

    return(alphas = view(alphas, :, 1:i), betas = view(betas, :, 1:i), gammas = view(gammas, :, 1:i), pct_dev = pct_dev[1:i], Î» = Î»_seq[1:i], fitted_values = view(fitted_means, :, 1:i))
end

# Function to perform coordinate descent with a lasso penalty
function cd_lasso(
    # positional arguments
    X::Matrix{T},
    G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}},
    Î»::T;
    #keywords arguments
    family::UnivariateDistribution,
    r::Vector{T},
    Î±::SparseVector{T},
    Î²::SparseVector{T},
    Î´::Vector{T},
    Ytilde::Vector{T},
    y::Vector{Int},
    w::Vector{T}, 
    eigvals::Vector{T}, 
    p_fX::Vector{T},
    p_fG::Vector{T},
    cd_maxiter::Integer = 10000,
    cd_tol::Real=1e-7,
    criterion,
    kwargs...
    ) where T

    converged = true
    loss = Inf

    # Compute sum of squares
    Swxx, Swgg = zero(Î±), zero(Î²)

    # Non-genetic effects
    for j in Î±.nzind
        @inbounds Swxx[j] = compute_Swxx(X, w, j)
    end

    # Genetic effects
    for j in Î².nzind
        @inbounds Swgg[j] = compute_Swxx(G, w, j)
    end

    # Coordinate descent algorithm
    for cd_iter in 1:cd_maxiter

        # Perform one coordinate descent cycle
        maxÎ” = cycle(X, G, Î», Val(false), r = r, Î± = Î±, Î² = Î², Swxx = Swxx, Swgg = Swgg, w = w, p_fX = p_fX, p_fG = p_fG)

        # Check termination condition before last iteration
        if criterion == :obj
            # Update Î¼
            Î¼, = updateÎ¼(r, Ytilde)

            # Update deviance and loss function
            prev_loss = loss
            dev = model_dev(family, Î´, w, r, eigvals, y, Î¼)
            loss = dev/2 + Î» * P(Î±, Î², p_fX, p_fG)

            # Check termination condition
            converged && abs(loss - prev_loss) < cd_tol * loss && break
            converged = abs(loss - prev_loss) < cd_tol * loss 

        elseif criterion == :coef
            converged && maxÎ” < cd_tol && break
            converged = maxÎ” < cd_tol
        end
    end

    # Assess convergence of coordinate descent
    @assert converged "Coordinate descent failed to converge in $cd_maxiter iterations at Î» = $Î»"

    return(Swxx, Swgg)
end

function cd_lasso(
    # positional arguments
    D::Vector{T},
    X::Matrix{T},
    G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}},
    Î»::T;
    #keywords arguments
    family::UnivariateDistribution,
    r::Vector{T},
    Î±::SparseVector{T},
    Î²::SparseVector{T},
    Î´::Vector{T},
    Î³::SparseVector{T},
    Ytilde::Vector{T},
    y::Vector{Int},
    w::Vector{T}, 
    eigvals::Vector{T}, 
    p_fX::Vector{T},
    p_fG::Vector{T},
    cd_maxiter::Integer = 10000,
    cd_tol::Real=1e-7,
    criterion,
    ) where T

    converged = true
    loss = Inf

    # Compute sum of squares
    Swxx, Swgg, Swdg = zero(Î±), zero(Î²), zero(Î³)

    # Non-genetic effects
    for j in Î±.nzind
        @inbounds Swxx[j] = compute_Swxx(X, w, j)
    end

    # Genetic effects
    for j in Î².nzind
        @inbounds Swgg[j] = compute_Swxx(G, w, j)
    end

    # GEI effects
    for j in Î³.nzind
        @inbounds Swdg[j] = compute_Swxx(D, G, w, j)
    end


    # Coordinate descent algorithm
    for cd_iter in 1:cd_maxiter

        # Perform one coordinate descent cycle
        maxÎ”, = cycle(D, X, G, Î», Val(false), r = r, Î± = Î±, Î² = Î², Î³ = Î³, Swxx = Swxx, Swgg = Swgg, Swdg = Swdg, w = w, p_fX = p_fX, p_fG = p_fG)

        # Check termination condition before last iteration
        if criterion == :obj
            # Update Î¼
            Î¼, = updateÎ¼(r, Ytilde)

            # Update deviance and loss function
            prev_loss = loss
            dev = model_dev(family, Î´, w, r, eigvals, y, Î¼)
            loss = dev/2 + Î» * P(Î±, Î², Î³, p_fX, p_fG)

            # Check termination condition
            converged && abs(loss - prev_loss) < cd_tol * loss && break
            converged = abs(loss - prev_loss) < cd_tol * loss 

        elseif criterion == :coef
            converged && maxÎ” < cd_tol && break
            converged = maxÎ” < cd_tol
        end
    end

    # Assess convergence of coordinate descent
    @assert converged "Coordinate descent failed to converge in $cd_maxiter iterations at Î» = $Î»"

    return(Swxx, Swgg, Swdg)
end

function cd_lasso(
    # positional arguments
    U::Matrix{T},
    Î»::T;
    #keywords arguments
    family::UnivariateDistribution,
    r::Vector{T},
    Î´::Vector{T},
    Ytilde::Vector{T},
    y::Vector{Int},
    w::Vector{T},
    eigvals::Vector{T}, 
    cd_maxiter::Integer = 10000,
    cd_tol::Real=1e-7,
    criterion
    ) where T

    converged = true
    loss = Inf

    # Compute sum of squares
    Swuu = zero(Î´)
    for j in 1:length(Î´)
        @inbounds Swuu[j] = compute_Swxx(U, w, j)
    end

    # Coordinate descent algorithm
    for cd_iter in 1:cd_maxiter

        # Perform one coordinate descent cycle
        maxÎ” = cycle(U, Î», r = r, Î´ = Î´, Swuu = Swuu, w = w, eigvals = eigvals)

        # Check termination condition before last iteration
        if criterion == :obj
            # Update Î¼
            Î¼, = updateÎ¼(r, Ytilde)

            # Update deviance and loss function
            prev_loss = loss
            dev = model_dev(family, Î´, w, r, eigvals, y, Î¼)
            loss = dev/2 + Î» * P(Î±, Î², Î³, p_fX, p_fG)

            # Check termination condition
            converged && abs(loss - prev_loss) < cd_tol * loss && break
            converged = abs(loss - prev_loss) < cd_tol * loss 

        elseif criterion == :coef
            converged && maxÎ” < cd_tol && break
            converged = maxÎ” < cd_tol
        end
    end

    # Assess convergence of coordinate descent
    @assert converged "Coordinate descent failed to converge in $cd_maxiter iterations at Î» = $Î»"

end

function cycle(
    # positional arguments
    X::Matrix{T},
    G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}},
    Î»::T,
    all_pred::Val{false};
    #keywords arguments
    r::Vector{T},
    Î±::SparseVector{T},
    Î²::SparseVector{T},
    Swxx::SparseVector{T},
    Swgg::SparseVector{T},
    w::Vector{T}, 
    p_fX::Vector{T},
    p_fG::Vector{T}
    ) where T

    maxÎ” = zero(T)

    # Cycle over coefficients in active set only until convergence
    # Non-genetic covariates
    for j in Î±.nzind
        last_Î± = Î±[j]
        v = compute_grad(X, w, r, j) + last_Î± * Swxx[j]
        new_Î± = softtreshold(v, Î» * p_fX[j]) / Swxx[j]
        r = update_r(X, r, last_Î± - new_Î±, j)

        maxÎ” = max(maxÎ”, Swxx[j] * (last_Î± - new_Î±)^2)
        Î±[j] = new_Î±
    end

    # Genetic predictors
    for j in Î².nzind
        last_Î² = Î²[j]
        v = compute_grad(G, w, r, j) + last_Î² * Swgg[j]
        new_Î² = softtreshold(v, Î» * p_fG[j]) / Swgg[j]
        r = update_r(G, r, last_Î² - new_Î², j)

        maxÎ” = max(maxÎ”, Swgg[j] * (last_Î² - new_Î²)^2)
        Î²[j] = new_Î²
    end

    maxÎ”
end

function cycle(
    # positional arguments
    D::Vector{T},
    X::Matrix{T},
    G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}},
    Î»::T,
    all_pred::Val{false};
    #keywords arguments
    r::Vector{T},
    Î±::SparseVector{T},
    Î²::SparseVector{T},
    Î³::SparseVector{T},
    Swxx::SparseVector{T},
    Swgg::SparseVector{T},
    Swdg::SparseVector{T},
    w::Vector{T}, 
    p_fX::Vector{T},
    p_fG::Vector{T}
    ) where T

    maxÎ” = zero(T)

    # Cycle over coefficients in active set only until convergence
    # Non-genetic covariates
    for j in Î±.nzind
        last_Î± = Î±[j]
        v = compute_grad(X, w, r, j) + last_Î± * Swxx[j]
        new_Î± = softtreshold(v, Î» * p_fX[j]) / Swxx[j]
        r = update_r(X, r, last_Î± - new_Î±, j)

        maxÎ” = max(maxÎ”, Swxx[j] * (last_Î± - new_Î±)^2)
        Î±[j] = new_Î±
    end

    # GEI and genetic effects
    for j in Î³.nzind
        Î»j = Î» * p_fG[j]

        # Update GEI effect
        last_Î³ = Î³[j]
        v = compute_grad(D, G, w, r, j) + last_Î³ * Swdg[j]
        if abs(v) > Î»j
            new_Î³ = softtreshold(v, Î»j) / (Swdg[j] + Î»j / norm((Î³[j], Î²[j])))
            r = update_r(D, G, r, last_Î³ - new_Î³, j)

            maxÎ” = max(maxÎ”, Swdg[j] * (last_Î³ - new_Î³)^2)
            Î³[j] = new_Î³
        end

        # Update genetic effect
        last_Î² = Î²[j]
        v = compute_grad(G, w, r, j) + last_Î² * Swgg[j]
        new_Î² = Î³[j] != 0 ? v / (Swgg[j] + Î»j / norm((Î³[j], Î²[j]))) : softtreshold(v, Î»j) / Swgg[j]
        r = update_r(G, r, last_Î² - new_Î², j)

        maxÎ” = max(maxÎ”, Swgg[j] * (last_Î² - new_Î²)^2)
        Î²[j] = new_Î²

    end

    maxÎ”
end

function cycle(
    # positional arguments
    X::Matrix{T},
    G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}},
    Î»::T,
    all_pred::Val{true};
    #keywords arguments
    r::Vector{T},
    Î±::SparseVector{T},
    Î²::SparseVector{T},
    Swxx::SparseVector{T},
    Swgg::SparseVector{T},
    w::Vector{T}, 
    p_fX::Vector{T},
    p_fG::Vector{T}
    ) where T

    maxÎ” = zero(T)
    kkt_check = true

    # At first and last iterations, cycle through all predictors
    # Non-genetic covariates
    for j in 1:length(Î±)
        v = compute_grad(X, w, r, j)
        Î»j = Î» * p_fX[j]
        
        if j in Î±.nzind
            last_Î± = Î±[j]
            v += last_Î± * Swxx[j]
        else
            # Adding a new variable to the model
            abs(v) <= Î»j && continue
            kkt_check = false
            last_Î± = 0
            Swxx[j] = compute_Swxx(X, w, j)
        end
        new_Î± = softtreshold(v, Î»j) / Swxx[j]
        r = update_r(X, r, last_Î± - new_Î±, j)

        maxÎ” = max(maxÎ”, Swxx[j] * (last_Î± - new_Î±)^2)
        Î±[j] = new_Î±
    end

    # Genetic covariates
    for j in 1:length(Î²)
        v = compute_grad(G, w, r, j)
        Î»j = Î» * p_fG[j]

        if j in Î².nzind
            last_Î² = Î²[j]
            v += last_Î² * Swgg[j]
        else
            # Adding a new variable to the model
            abs(v) <= Î»j && continue
            kkt_check = false
            last_Î² = 0
            Swgg[j] = compute_Swxx(G, w, j)
        end
        new_Î² = softtreshold(v, Î»j) / Swgg[j]
        r = update_r(G, r, last_Î² - new_Î², j)

        maxÎ” = max(maxÎ”, Swgg[j] * (last_Î² - new_Î²)^2)
        Î²[j] = new_Î²
    end

    return(maxÎ”, kkt_check)
end

function cycle(
    # positional arguments
    D::Vector{T},
    X::Matrix{T},
    G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}},
    Î»::T,
    all_pred::Val{true};
    #keywords arguments
    r::Vector{T},
    Î±::SparseVector{T},
    Î²::SparseVector{T},
    Î³::SparseVector{T},
    Swxx::SparseVector{T},
    Swgg::SparseVector{T},
    Swdg::SparseVector{T},
    w::Vector{T}, 
    p_fX::Vector{T},
    p_fG::Vector{T}
    ) where T

    maxÎ” = zero(T)
    kkt_check = true

    # At first and last iterations, cycle through all predictors
    # Non-genetic covariates
    for j in 1:length(Î±)
        v = compute_grad(X, w, r, j)
        Î»j = Î» * p_fX[j]
        
        if j in Î±.nzind
            last_Î± = Î±[j]
            v += last_Î± * Swxx[j]
        else
            # Adding a new variable to the model
            abs(v) <= Î»j && continue
            kkt_check = false
            last_Î± = 0
            Swxx[j] = compute_Swxx(X, w, j)
        end
        new_Î± = softtreshold(v, Î»j) / Swxx[j]
        r = update_r(X, r, last_Î± - new_Î±, j)

        maxÎ” = max(maxÎ”, Swxx[j] * (last_Î± - new_Î±)^2)
        Î±[j] = new_Î±
    end

    # GEI and genetic effects
    for j in 1:length(Î³)
        v = compute_grad(D, G, w, r, j)
        Î»j = Î» * p_fG[j]

        if j in Î³.nzind || abs(v) > Î»j
            # Update GEI effect
            if j in Î³.nzind 
                last_Î³ = Î³[j]
                v += last_Î³ * Swdg[j]
            else
                kkt_check = false
                last_Î³, Î³[j] = 0, 1
                Swdg[j] = compute_Swxx(D, G, w, j)
            end

            new_Î³ = softtreshold(v, Î»j) / (Swdg[j] + Î»j / norm((last_Î³, Î²[j])))
            r = update_r(D, G, r, last_Î³ - new_Î³, j)

            # Update genetic effect
            v = compute_grad(G, w, r, j)

            if j in Î².nzind 
                last_Î² = Î²[j]
                v += last_Î² * Swgg[j]
            else
                kkt_check = false
                last_Î², Î²[j] = 0, 1
                Swgg[j] = compute_Swxx(G, w, j)
            end

            new_Î² = new_Î³ != 0 ? v / (Swgg[j] + Î»j / norm((last_Î³, last_Î²))) : softtreshold(v, Î»j) / Swgg[j]
            r = update_r(G, r, last_Î² - new_Î², j)

            maxÎ” = max(maxÎ”, Swgg[j] * (last_Î² - new_Î²)^2, Swdg[j] * (last_Î³ - new_Î³)^2)
            Î²[j], Î³[j] = new_Î², new_Î³

            continue
        end

        # Genetic effects only
        v = compute_grad(G, w, r, j)

        if j in Î².nzind
            last_Î² = Î²[j]
            v += last_Î² * Swgg[j]
        else
            # Adding a new variable to the model
            abs(v) <= Î»j && continue
            kkt_check = false
            last_Î² = 0
            Swgg[j] = compute_Swxx(G, w, j)
        end
        new_Î² = softtreshold(v, Î»j) / Swgg[j]
        r = update_r(G, r, last_Î² - new_Î², j)

        maxÎ” = max(maxÎ”, Swgg[j] * (last_Î² - new_Î²)^2)
        Î²[j] = new_Î²

    end

    return(maxÎ”, kkt_check)
end

function cycle(
    # positional arguments
    U::Matrix{T},
    Î»::T;
    #keywords arguments
    r::Vector{T},
    Î´::Vector{T},
    Swuu::Vector{T},
    w::Vector{T}, 
    eigvals::Vector{T}
    ) where T

    maxÎ” = zero(T)

    # Cycle through all predictors
    for j in 1:size(U, 2)
        last_Î´ = Î´[j]
        v = compute_grad(U, w, r, j) + last_Î´ * Swuu[j]
        new_Î´ = v / (Swuu[j] + eigvals[j])
        r = update_r(U, r, last_Î´ - new_Î´, j)

        maxÎ” = max(maxÎ”, Swuu[j] * (last_Î´ - new_Î´)^2)
        Î´[j] = new_Î´
    end

    maxÎ”
end

# Function to update random effects vector
function update_Î´(
    # positional arguments
    ::Val{:cd};
    #keywords arguments
    U::Matrix{T}, 
    Î»::T, 
    family::UnivariateDistribution, 
    Ytilde::Vector{T}, 
    y::Vector{Int64}, 
    w::Vector{T}, 
    r::Vector{T}, 
    Î´::Vector{T}, 
    eigvals::Vector{T}, 
    criterion = criterion,
    kwargs...
    ) where T

    cd_lasso(U, Î»; family = family, Ytilde = Ytilde, y = y, w = w, r = r, Î´ = Î´, eigvals = eigvals, criterion = criterion)
end

function update_Î´(
    # positional arguments
    ::Val{:conjgrad};
    #keywords arguments
    U::Matrix{T},
    y::Vector{Int64}, 
    w::Vector{T}, 
    r::Vector{T}, 
    Î´::Vector{T}, 
    eigvals::Vector{T}, 
    Î¼::Vector{T},
    kwargs...
    ) where T

    delta_Î´ = conjgrad(Î´ = Î´, eigvals = eigvals, U = U, y = y, Î¼ = Î¼, w = w)
    r += U * delta_Î´
end

# Conjuguate gradient descent to update random effects vector
function conjgrad(
    ;
    #keywords arguments
    Î´::Vector{T},
    eigvals::Vector{T},
    U::Matrix{T},
    y::Vector{Int64},
    Î¼::Vector{T},
    w::Vector{T},
    tol::T = 1e-7
    ) where T
    
    # Initialization
    converged = false 
    A = U' * Diagonal(w) * U + Diagonal(eigvals)
    r = eigvals .* Î´ - U' * (y - Î¼)
    p = -r
    k, delta_Î´ = 0, zero(Î´)

    for _ in 1:size(U, 1)
        # Check convergence
        converged = norm(r) < tol
        # converged && println("Conjuguate gradient has converged in $k steps.") 
        converged && break

        # Next iteration
        k += 1
        alpha = dot(r, r) / dot(p, A, p) 
        new_Î´ = Î´ + alpha * p
        delta_Î´ += Î´ - new_Î´
        Î´ = new_Î´
        new_r = r + alpha * A * p
        beta = dot(new_r, new_r) / dot(r, r)
        r = new_r
        p = -r + beta * p
    end

    @assert converged "Conjuguate gradient descent failed to converge."
    delta_Î´
end

modeltype(::Normal) = "Least Squares GLMNet"
modeltype(::Binomial) = "Logistic"

struct pglmmPath{F<:Distribution, A<:AbstractArray, B<:AbstractArray, T<:AbstractFloat, C<:SubArray{T, 2, Matrix{T}, Tuple{Base.Slice{Base.OneTo{Int}}, UnitRange{Int}}, true}}
    family::F
    a0::A                                       # intercept values for each solution
    alphas::B                                   # coefficient values for each solution
    betas::Union{B, C}                                 
    gammas::Union{Nothing, C}
    null_dev::T                                 # Null deviance of the model
    pct_dev::A                                  # R^2 values for each solution
    lambda::A                                   # lamda values corresponding to each solution
    npasses::Int                                # actual number of passes over the
                                                # data for all lamda values
    fitted_values                               # fitted_values
    y::Union{Vector{Int}, A}                    # eigenvalues vector
    UD_invUt::B                                 # eigenvectors matrix times diagonal weights matrix
    Ï„::A                                        # estimated variance components
    intercept::Bool                             # boolean for intercept
end

function show(io::IO, g::pglmmPath)
    if isnothing(g.gammas)
        df = [length(findall(x -> x != 0, vec(view([g.alphas; g.betas], :,k)))) for k in 1:size(g.betas, 2)]
        println(io, "$(modeltype(g.family)) Solution Path ($(size(g.betas, 2)) solutions for $(size([g.alphas; g.betas], 1)) predictors):") #in $(g.npasses) passes):"
    else
        df = [length(findall(x -> x != 0, vec(view([g.alphas; g.betas; g.gammas], :,k)))) for k in 1:size(g.betas, 2)]
        println(io, "$(modeltype(g.family)) Solution Path ($(size(g.betas, 2)) solutions for $(size([g.alphas; g.betas; g.gammas], 1)) predictors):") #in $(g.npasses) passes):"
    end    
    print(io, CoefTable(Union{Vector{Int},Vector{Float64}}[df, g.pct_dev, g.lambda], ["df", "pct_dev", "Î»"], []))
end

# Function to compute sequence of values for Î»
function lambda_seq(
    r::Vector{T}, 
    X::Matrix{T},
    G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}},
    D::Union{Vector{T}, Nothing}; 
    p_fX::Vector{T},
    p_fG::Vector{T},
    K::Integer = 100
    ) where T

    Î»_min_ratio = (length(r) < size(G, 2) ? 1e-2 : 1e-4)
    Î»_max = lambda_max(nothing, X, r, p_fX)
    Î»_max = lambda_max(D, G, r, p_fG, Î»_max)
    Î»_min = Î»_max * Î»_min_ratio
    Î»_step = log(Î»_min_ratio)/(K - 1)
    Î»_seq = exp.(collect(log(Î»_max+100*eps(Î»_max)):Î»_step:log(Î»_min)))

    Î»_seq
end

# Function to compute Î»_max for the lasso
function lambda_max(D::Nothing, X::AbstractMatrix{T}, r::AbstractVector{T}, p_f::AbstractVector{T}, Î»_max::T = zero(T)) where T
    seq = findall(!iszero, p_f)
    for j in seq
        x = abs(compute_grad(X, r, j))
        if x > Î»_max
            Î»_max = x
        end
    end
    return(Î»_max)
end

# Function to compute Î»_max for the group lasso
function lambda_max(D::AbstractVector{T}, X::AbstractMatrix{T}, r::AbstractVector{T}, p_f::AbstractVector{T}, Î»_max::T = zero(T)) where T

    seq = findall(!iszero, p_f)
    for j in seq
        x = compute_max(D, X, r, j)
        if x > Î»_max
            Î»_max = x
        end
    end
    return(Î»_max)
end

# Define softtreshold function
function softtreshold(z::T, Î³::T) :: T where T
    if z > Î³
        z - Î³
    elseif z < -Î³
        z + Î³
    else
        0
    end
end

# Function to update working response and residual
function wrkresp(
    y::Vector{Int64},
    Î¼::Vector{T},
    w::Vector{T}
) where T
    Î· = GLM.linkfun.(LogitLink(), Î¼)
    Ytilde = [Î·[i] + (y[i] - Î¼[i]) / w[i] for i in 1:length(y)]
    r = Ytilde - Î·
    return(Ytilde, r)
end

# Function to update linear predictor and mean at each iteration
const PMIN = 1e-5
const PMAX = 1-1e-5
function updateÎ¼(r::Vector{T}, Ytilde::Vector{T}) where T
    Î· = Ytilde - r
    Î¼ = GLM.linkinv.(LogitLink(), Î·)
    Î¼ = [Î¼[i] < PMIN ? PMIN : Î¼[i] > PMAX ? PMAX : Î¼[i] for i in 1:length(Î¼)]
    w = Î¼ .* (1 .- Î¼)
    return(Î¼, w)
end

# Functions to calculate deviance
model_dev(::Binomial, Î´::Vector{T}, w::Vector{T}, r::Vector{T}, eigvals::Vector{T}, y::Vector{Int64}, Î¼::Vector{Float64}) where T = LogisticDeviance(Î´, eigvals, y, Î¼)
model_dev(::Normal, Î´::Vector{T}, w::T, r::Vector{T}, eigvals::Vector{T}, kargs...) where T = NormalDeviance(Î´, w, r, eigvals)

function LogisticDeviance(Î´::Vector{T}, eigvals::Vector{T}, y::Vector{Int64}, Î¼::Vector{T}) where T
    -2 * sum(y .* log.(Î¼ ./ (1 .- Î¼)) .+ log.(1 .- Î¼)) + dot(Î´, Diagonal(eigvals), Î´)
end

function NormalDeviance(Î´::Vector{T}, w::T, r::Vector{T}, eigvals::Vector{T}) where T
    w * dot(r, r) + dot(Î´, Diagonal(eigvals), Î´)
end

# Predict phenotype
function predict(path::pglmmPath, 
                  X::AbstractMatrix{T}, 
                  grmfile::AbstractString; 
                  grmrowinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  grmcolinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  M::Union{Nothing, Vector{Any}} = nothing,
                  s::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  fixed_effects_only::Bool = false,
                  outtype = :response
                 ) where T

    # read file containing the m x (N-m) kinship matrix between m test and (N-m) training subjects
    GRM = open(GzipDecompressorStream, grmfile, "r") do stream
        Symmetric(Matrix(CSV.read(stream, DataFrame)))
    end

    if !isnothing(grmrowinds)
        GRM = GRM[grmrowinds, :]
    end

    if !isnothing(grmcolinds)
        GRM = GRM[:, grmcolinds]
    end

    # Covariance matrix between test and training subjects
    V = isnothing(M) ? push!(Any[], GRM) : reverse(push!(M, GRM))
    Î£_12 = sum(path.Ï„ .* V)

    # Number of predictions to compute. User can provide index s for which to provide predictions, 
    # rather than computing predictions for the whole path.
    s = isnothing(s) ? (1:size(path.betas, 2)) : s

    # Linear predictor
    Î· = !isnothing(path.gammas) ? path.a0[s]' .+ X * [path.alphas; path.betas; path.gammas][:,s] : path.a0[s]' .+ X * [path.alphas; path.betas][:,s]

    if fixed_effects_only == false
        if path.family == Binomial()
            Î· += Î£_12 * (path.y .- path.fitted_values[:,s])
        elseif path.family == Normal()
            Î· += Î£_12 * path.UD_invUt * path.fitted_values[:,s]
        end
    end

    # Return linear predictor (default) or fitted probs
    if outtype == :response
        return(Î·)
    elseif outtype == :prob
        return(GLM.linkinv.(LogitLink(), Î·))
    end
end 

function predict(path::pglmmPath, 
                  covfile::AbstractString,
                  grmfile::AbstractString,
                  plinkfile::Union{Nothing, AbstractString} = nothing;
                  # keyword arguments
                  snpfile::Union{Nothing, AbstractString} = nothing,
                  snpmodel = ADDITIVE_MODEL,
                  snpinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  covrowinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  covars::Union{Nothing,AbstractVector{<:String}} = nothing, 
                  geneticrowinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  grmrowinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  grmcolinds::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  M::Union{Nothing, Vector{Any}} = nothing,
                  s::Union{Nothing,AbstractVector{<:Integer}} = nothing,
                  fixed_effects_only::Bool = false,
                  GEIvar::Union{Nothing,AbstractString} = nothing,
                  outtype = :response
                 ) where T
    
    #--------------------------------------------------------------
    # Read covariate file
    #--------------------------------------------------------------
    covdf = CSV.read(covfile, DataFrame)

    if !isnothing(covrowinds)
        covdf = covdf[covrowinds,:]
    end 

    if !isnothing(covars)
        covdf = covdf[:, covars]
    end 

    X = Matrix(covdf)
    nX, k =size(X)

    #--------------------------------------------------------------
    # Read file containing the m x (N-m) kinship matrix between m test and (N-m) training subjects
    #--------------------------------------------------------------
    GRM = open(GzipDecompressorStream, grmfile, "r") do stream
        Symmetric(Matrix(CSV.read(stream, DataFrame)))
    end

    if !isnothing(grmrowinds)
        GRM = GRM[grmrowinds, :]
    end

    if !isnothing(grmcolinds)
        GRM = GRM[:, grmcolinds]
    end

    @assert nX == size(GRM, 1) "GRM and covariates matrix must have same number of rows."
    
    #--------------------------------------------------------------
    # Read genotype file
    #--------------------------------------------------------------
    if !isnothing(plinkfile)

        # read PLINK files
        geno = SnpArray(plinkfile * ".bed")
    
        # Convert genotype file to matrix, convert to additive model (default) and impute
        snpinds_ = isnothing(snpinds) ? (1:size(geno, 2)) : snpinds 
        geneticrowinds_ = isnothing(geneticrowinds) ? (1:size(geno, 1)) : geneticrowinds
        geno = isnothing(snpinds) && isnothing(geneticrowinds) ? geno : SnpArrays.filter(plinkfile, geneticrowinds_, snpinds_)
        
        # Read genotype
        G = SnpLinAlg{Float64}(geno, model = snpmodel, impute = true, center = false, scale = false)

    elseif !isnothing(snpfile)

        # read CSV file
        geno = CSV.read(snpfile, DataFrame)
        
        # Convert genotype file to matrix, convert to additive model (default) and impute
        snpinds_ = isnothing(snpinds) ? (1:size(geno, 2)) : snpinds 
        geneticrowinds_ = isnothing(geneticrowinds) ? (1:size(geno, 1)) : geneticrowinds
        G = convert.(Float64, Matrix(geno[geneticrowinds_, snpinds_]))

    end

    # Initialize number of subjects and predictors (including intercept)
    nG, p = size(G)
    @assert nG == size(GRM, 1) "GRM and genotype matrix must have same number of rows."
    
    #--------------------------------------------------------------
    # Compute predictions
    #--------------------------------------------------------------
    # Covariance matrix between test and training subjects
    V = isnothing(M) ? push!(Any[], GRM) : reverse(push!(M, GRM))
    Î£_12 = sum(path.Ï„ .* V)

    # Number of predictions to compute. User can provide index s for which to provide predictions, 
    # rather than computing predictions for the whole path.
    s = isnothing(s) ? (1:size(path.betas, 2)) : s

    # Linear predictor
    Î· = path.a0[s]' .+ X * path.alphas[:,s] .+ G * path.betas[:,s]

    if !isnothing(GEIvar)
        D = covdf[:, GEIvar]
        Î· += (D .* G) * path.gammas[:,s]
    end

    if fixed_effects_only == false
        if path.family == Binomial()
            Î· += Î£_12 * (path.y .- path.fitted_values[:,s])
        elseif path.family == Normal()
            Î· += Î£_12 * path.UD_invUt * path.fitted_values[:,s]
        end
    end

    # Return linear predictor (default) or fitted probs
    if outtype == :response
        return(Î·)
    elseif outtype == :prob
        return(GLM.linkinv.(LogitLink(), Î·))
    end
end 

# GIC penalty parameter
function GIC(path::pglmmPath, criterion)
    
    # Obtain number of rows (n), predictors (p) and Î» values (K)
    n = size(path.y, 1)
    m, (p, K) = size(path.alphas, 1), size(path.betas)
    df = path.intercept .+ [length(findall(x -> x != 0, vec(view([path.alphas; path.betas], :, k)))) for k in 1:K] .+ length(path.Ï„)
    df += !isnothing(path.gammas) ? [length(findall(x -> x != 0, vec(view(path.gammas, :, k)))) for k in 1:K] : zero(df)

    # Define GIC criterion
    if criterion == :BIC
        a_n = log(n)
    elseif criterion == :AIC
        a_n = 2
    elseif criterion == :HDBIC
        a_n = !isnothing(path.gammas) ? log(log(n)) * log(m + 2 * p) : log(log(n)) * log(m + p)
    end

    # Compute deviance for each value of Î»
    dev = (1 .- path.pct_dev) * path.null_dev
    GIC = dev .+ a_n * df

    # Return betas with lowest GIC value
    return(argmin(GIC))
end

# Standardize predictors for lasso
function standardizeX(X::AbstractMatrix{T}, standardize::Bool, intercept::Bool = false) where T
    mu = intercept ? vec([0 mean(X[:,2:end], dims = 1)]) : vec(mean(X, dims = 1))
    if standardize
        s = intercept ? vec([1 std(X[:,2:end], dims = 1, corrected = false)]) : vec(std(X, dims = 1, corrected = false)) 
        if any(s .== zero(T))
            @warn("One predictor is a constant, hence it can't been standardized!")
            s[s .== 0] .= 1 
        end
        for j in 1:size(X,2), i in 1:size(X, 1) 
            @inbounds X[i,j] = (X[i,j] .- mu[j]) / s[j]
        end
    else
        for j in 1:size(X,2), i in 1:size(X, 1) 
            @inbounds X[i,j] = X[i,j] .- mu[j]
        end
        s = []
    end

    # Remove first term if intercept
    if intercept 
         popfirst!(mu); popfirst!(s)
    end

    X, mu, s
end

# Calculate mean and scale for genotype data
function standardizeG(s::AbstractSnpArray, model, scale::Bool, T = AbstractFloat)
    n, m = size(s)
    Î¼, Ïƒ = Array{T}(undef, m), Array{T}(undef, m)	
    @inbounds for j in 1:m
        Î¼j, mj = zero(T), 0
        for i in 1:n
            vij = SnpArrays.convert(T, s[i, j], model)
            Î¼j += isnan(vij) ? zero(T) : vij
            mj += isnan(vij) ? 0 : 1
        end
        Î¼j /= mj
        Î¼[j] = Î¼j
        Ïƒ[j] = model == ADDITIVE_MODEL ? sqrt(Î¼j * (1 - Î¼j / 2)) : sqrt(Î¼j * (1 - Î¼j))
    end
    
    # Return centre and scale parameters
    if scale 
	   return Î¼, Ïƒ
    else 
	   return Î¼, []
    end
end

function compute_grad(X::AbstractMatrix{T}, w::AbstractVector{T}, r::AbstractVector{T}, whichcol::Int) where T
    v = zero(T)
    for i = 1:size(X, 1)
        @inbounds v += X[i, whichcol] * r[i] * w[i]
    end
    v
end

function compute_grad(D::AbstractVector{T}, X::AbstractMatrix{T}, w::AbstractVector{T}, r::AbstractVector{T}, whichcol::Int) where T
    v = zero(T)
    for i = 1:size(X, 1)
        @inbounds v += D[i] * X[i, whichcol] * r[i] * w[i]
    end
    v
end

function compute_grad(X::AbstractMatrix{T}, r::AbstractVector{T}, whichcol::Int) where T
    v = zero(T)
    for i = 1:size(X, 1)
        @inbounds v += X[i, whichcol] * r[i]
    end
    v
end

function compute_max(D::AbstractVector{T}, X::AbstractMatrix{T}, r::AbstractVector{T}, whichcol::Int) where T
    v = zeros(2)
    for i = 1:size(X, 1)
        @inbounds v[1] += X[i, whichcol] * r[i]
        @inbounds v[2] += D[i] * X[i, whichcol] * r[i]
    end
    maximum(abs.(v))
end

function compute_prod(X::AbstractMatrix{T}, y::AbstractVector{Int}, p::AbstractVector{T}, whichcol::Int) where T
    v = zero(T)
    for i = 1:size(X, 1)
        @inbounds v += X[i, whichcol] * (y[i] - p[i])
    end
    v
end

function compute_prod(D::AbstractVector{T}, X::AbstractMatrix{T}, y::AbstractVector{Int}, p::AbstractVector{T}, whichcol::Int) where T
    v = zero(T)
    for i = 1:size(X, 1)
        @inbounds v += D[i] * X[i, whichcol] * (y[i] - p[i])
    end
    v
end

function compute_Swxx(X::AbstractMatrix{T}, w::AbstractVector{T}, whichcol::Int) where T
    s = zero(T)
    for i = 1:size(X, 1)
        @inbounds s += X[i, whichcol]^2 * w[i]
    end
    s
end

function compute_Swxx(D::AbstractVector{T}, X::AbstractMatrix{T}, w::AbstractVector{T}, whichcol::Int) where T
    s = zero(T)
    for i = 1:size(X, 1)
        @inbounds s += (D[i] * X[i, whichcol])^2 * w[i]
    end
    s
end

function update_r(X::AbstractMatrix{T}, r::AbstractVector{T}, deltaÎ²::T, whichcol::Int) where T
    for i = 1:size(X, 1)
        @inbounds r[i] += X[i, whichcol] * deltaÎ²
    end
    r
end

function update_r(D::AbstractVector{T}, X::AbstractMatrix{T}, r::AbstractVector{T}, deltaÎ²::T, whichcol::Int) where T
    for i = 1:size(X, 1)
        @inbounds r[i] += D[i] * X[i, whichcol] * deltaÎ²
    end
    r
end

function P(Î±::SparseVector{T}, Î²::SparseVector{T}, p_fX::Vector{T}, p_fG::Vector{T}) where T
    x = zero(T)
    @inbounds @simd for i in Î±.nzind
            x += p_fX[i] * abs(Î±[i])
    end
    @inbounds @simd for i in Î².nzind
            x += p_fG[i] * abs(Î²[i])
    end
    x
end

function P(Î±::SparseVector{T}, Î²::SparseVector{T}, Î³::SparseVector{T}, p_fX::Vector{T}, p_fG::Vector{T}) where T
    x = zero(T)
    @inbounds @simd for i in Î±.nzind
            x += p_fX[i] * abs(Î±[i])
    end
    @inbounds @simd for i in Î².nzind
            x += p_fG[i] * (norm((Î²[i], Î³[i])) + abs(Î³[i]))
    end
    x
end

# Compute strongrule for the lasso
function compute_strongrule(dÎ»::T, p_fX::Vector{T}, p_fG::Vector{T}; Î±::SparseVector{T}, Î²::SparseVector{T}, X::Matrix{T}, G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}}, y::Vector{Int}, Î¼::Vector{T}) where T
    for j in 1:length(Î±)
        j in Î±.nzind && continue
        c = compute_prod(X, y, Î¼, j)
        abs(c) <= dÎ» * p_fX[j] && continue
        
        # Force a new variable to the model
        Î±[j] = 1; Î±[j] = 0
    end
    
    for j in 1:length(Î²)
        j in Î².nzind && continue
        c = compute_prod(G, y, Î¼, j)
        abs(c) <= dÎ» * p_fG[j] && continue
        
        # Force a new variable to the model
        Î²[j] = 1; Î²[j] = 0
    end
end

# Compute strongrule for the group lasso + lasso (CAP)
function compute_strongrule(dÎ»::T, Î»::T, p_fX::Vector{T}, p_fG::Vector{T}, D::Vector{T}; Î±::SparseVector{T}, Î²::SparseVector{T}, Î³::SparseVector{T}, X::Matrix{T}, G::SubArray{T, 2, SnpLinAlg{T}, Tuple{Vector{Int64}, UnitRange{Int64}}}, y::Vector{Int}, Î¼::Vector{T}) where T
    for j in 1:length(Î±)
        j in Î±.nzind && continue
        c = compute_prod(X, y, Î¼, j)
        abs(c) <= dÎ» * p_fX[j] && continue
        
        # Force a new variable to the model
        Î±[j] = 1; Î±[j] = 0
    end
    
    for j in 1:length(Î³)
        j in Î³.nzind && continue
        c1 = compute_prod(G, y, Î¼, j)
        c2 = softtreshold(compute_prod(D, G, y, Î¼, j), Î» * p_fG[j])
        norm([c1, c2]) <= dÎ» * p_fG[j] && continue
        
        # Force a new group to the model
        Î³[j] = 1; Î³[j] = 0
        j in Î².nzind && continue
        Î²[j] = 1; Î²[j] = 0
    end
end